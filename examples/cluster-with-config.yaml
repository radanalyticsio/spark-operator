apiVersion: v1
kind: ConfigMap
metadata:
  name: sparky-cluster                                  # compulsory
  labels:
    radanalytics.io/kind: sparkcluster                       # compulsory
data:
  config: |-
    worker:
      replicas: "2"                                    # optional defaults to 1
      limits:
        memory: "1Gi"                                       # optional no defaults
        cpu: 0.2                                            # optional no defaults
    master:
      replicas: "1"                                    # optional defaults to 1
      limits:
        memory: "1Gi"                                       # optional no defaults
        cpu: 0.2                                            # optional no defaults
    customImage: jkremser/openshift-spark:2.3-latest    # optional defaults to jkremser/openshift-spark:2.3-latest
    env:                                                # optional
    - name: SPARK_WORKER_CORES
      value: 2
    - name: FOO
      value: bar
    sparkConfigurationMap: my-config                    # optional defaults to ${name}-config
                                                        # kubectl create configmap my-config --from-file=example/config.conf
    sparkConfiguration:                                 # optional, it overrides the config defined above
    - name: spark.executor.memory
      value: 1g
    - name: spark.sql.conf.autoBroadcastJoinThreshold
      value: 20971520
    downloadData:                                       # optional, it downloads these files to each node
    - url: https://raw.githubusercontent.com/Jiri-Kremser/spark-operator/master/README.md
      to: /tmp/
